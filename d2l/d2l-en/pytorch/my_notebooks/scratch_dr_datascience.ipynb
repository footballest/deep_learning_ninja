{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cc9fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaac46fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " torch.Size([3, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([0, 1, 2]).reshape(-1, 1)\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb92611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1]]), torch.Size([1, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([0, 1]).reshape(1, -1)\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de2fa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbec3ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_data(w, b, num_examples):\n",
    "    X = torch.normal(0, 1,  size= (num_examples, len(w)))\n",
    "    y = torch.matmul(X,w) \n",
    "    y += b\n",
    "    y += torch.normal(0, 0.01, size=(y.shape))\n",
    "    return X, y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73faf44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(torch.normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcef452f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 2]), torch.Size([1000, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "N = 1000\n",
    "features, labels = synthetic_data(true_w, true_b, N)\n",
    "\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f357eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataLoader in module torch.utils.data.dataloader:\n",
      "\n",
      "class DataLoader(typing.Generic)\n",
      " |  DataLoader(dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[Sequence], Iterable[Sequence], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int] = None, persistent_workers: bool = False, pin_memory_device: str = '')\n",
      " |  \n",
      " |  Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      " |  the given dataset.\n",
      " |  \n",
      " |  The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      " |  iterable-style datasets with single- or multi-process loading, customizing\n",
      " |  loading order and optional automatic batching (collation) and memory pinning.\n",
      " |  \n",
      " |  See :py:mod:`torch.utils.data` documentation page for more details.\n",
      " |  \n",
      " |  Args:\n",
      " |      dataset (Dataset): dataset from which to load the data.\n",
      " |      batch_size (int, optional): how many samples per batch to load\n",
      " |          (default: ``1``).\n",
      " |      shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      " |          at every epoch (default: ``False``).\n",
      " |      sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      " |          samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      " |          implemented. If specified, :attr:`shuffle` must not be specified.\n",
      " |      batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      " |          returns a batch of indices at a time. Mutually exclusive with\n",
      " |          :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      " |          and :attr:`drop_last`.\n",
      " |      num_workers (int, optional): how many subprocesses to use for data\n",
      " |          loading. ``0`` means that the data will be loaded in the main process.\n",
      " |          (default: ``0``)\n",
      " |      collate_fn (Callable, optional): merges a list of samples to form a\n",
      " |          mini-batch of Tensor(s).  Used when using batched loading from a\n",
      " |          map-style dataset.\n",
      " |      pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      " |          into device/CUDA pinned memory before returning them.  If your data elements\n",
      " |          are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      " |          see the example below.\n",
      " |      drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      " |          if the dataset size is not divisible by the batch size. If ``False`` and\n",
      " |          the size of dataset is not divisible by the batch size, then the last batch\n",
      " |          will be smaller. (default: ``False``)\n",
      " |      timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      " |          from workers. Should always be non-negative. (default: ``0``)\n",
      " |      worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      " |          worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      " |          input, after seeding and before data loading. (default: ``None``)\n",
      " |      generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      " |          by RandomSampler to generate random indexes and multiprocessing to generate\n",
      " |          `base_seed` for workers. (default: ``None``)\n",
      " |      prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      " |          in advance by each worker. ``2`` means there will be a total of\n",
      " |          2 * num_workers batches prefetched across all workers. (default value depends\n",
      " |          on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      " |          Otherwise if value of num_workers>0 default is ``2``).\n",
      " |      persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
      " |          the worker processes after a dataset has been consumed once. This allows to\n",
      " |          maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      " |      pin_memory_device (str, optional): the data loader will copy Tensors\n",
      " |          into device pinned memory before returning them if pin_memory is set to true.\n",
      " |  \n",
      " |  \n",
      " |  .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      " |               cannot be an unpicklable object, e.g., a lambda function. See\n",
      " |               :ref:`multiprocessing-best-practices` on more details related\n",
      " |               to multiprocessing in PyTorch.\n",
      " |  \n",
      " |  .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      " |               When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      " |               it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      " |               rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      " |               configurations. This represents the best guess PyTorch can make because PyTorch\n",
      " |               trusts user :attr:`dataset` code in correctly handling multi-process\n",
      " |               loading to avoid duplicate data.\n",
      " |  \n",
      " |               However, if sharding results in multiple workers having incomplete last batches,\n",
      " |               this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      " |               be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      " |               dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      " |               cases in general.\n",
      " |  \n",
      " |               See `Dataset Types`_ for more details on these two types of datasets and how\n",
      " |               :class:`~torch.utils.data.IterableDataset` interacts with\n",
      " |               `Multi-process data loading`_.\n",
      " |  \n",
      " |  .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      " |               :ref:`data-loading-randomness` notes for random seed related questions.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataLoader\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[Sequence], Iterable[Sequence], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int] = None, persistent_workers: bool = False, pin_memory_device: str = '')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self) -> '_BaseDataLoaderIter'\n",
      " |      # We quote '_BaseDataLoaderIter' since it isn't defined yet and the definition can't be moved up\n",
      " |      # since '_BaseDataLoaderIter' references 'DataLoader'.\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |  \n",
      " |  __setattr__(self, attr, val)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  check_worker_number_rationality(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  multiprocessing_context\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_iterator': typing.Optional[ForwardRef('_BaseDataL...\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data.DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95e36e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TensorDataset in module torch.utils.data.dataset:\n",
      "\n",
      "class TensorDataset(Dataset)\n",
      " |  TensorDataset(*tensors: torch.Tensor) -> None\n",
      " |  \n",
      " |  Dataset wrapping tensors.\n",
      " |  \n",
      " |  Each sample will be retrieved by indexing tensors along the first dimension.\n",
      " |  \n",
      " |  Args:\n",
      " |      *tensors (Tensor): tensors that have the same size of the first dimension.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TensorDataset\n",
      " |      Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |  \n",
      " |  __init__(self, *tensors: torch.Tensor) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'tensors': typing.Tuple[torch.Tensor, ...]}\n",
      " |  \n",
      " |  __orig_bases__ = (torch.utils.data.dataset.Dataset[typing.Tuple[torch....\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Dataset:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data.TensorDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "130a50ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (3999097260.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    *b\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "b = (1, 2)\n",
    "*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ebf2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2807,  0.1441])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d282c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a Pytorch data iterator\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features,labels), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d54c667",
   "metadata": {},
   "outputs": [],
   "source": [
    " xs = [10, 20, 30] ## this is an iterable\n",
    " it = iter(xs)    ## this is an iterator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fff6048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.6448, -0.4955],\n",
       "         [ 0.1100, -0.9053],\n",
       "         [ 0.4761,  0.7436],\n",
       "         [ 1.1318, -0.2649],\n",
       "         [ 0.3704, -1.2170],\n",
       "         [-2.7935,  0.7753],\n",
       "         [ 0.3697,  1.1704],\n",
       "         [ 1.3909,  0.2014],\n",
       "         [-0.2749, -1.4179],\n",
       "         [ 1.2132, -0.3327]]),\n",
       " tensor([[ 4.5873],\n",
       "         [ 7.5036],\n",
       "         [ 2.6378],\n",
       "         [ 7.3694],\n",
       "         [ 9.0706],\n",
       "         [-4.0241],\n",
       "         [ 0.9793],\n",
       "         [ 6.2941],\n",
       "         [ 8.4685],\n",
       "         [ 7.7547]])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52f7430",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce1ffc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f2f8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42f5d1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1]),\n",
       " [Parameter containing:\n",
       "  tensor([[-0.6666, -0.1235]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.4765], requires_grad=True)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(features).shape, list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbc52406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[-0.6666, -0.1235]])),\n",
       "             ('0.bias', tensor([0.4765]))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f65fe1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=2, out_features=1, bias=True),\n",
       " [Parameter containing:\n",
       "  tensor([[-0.6666, -0.1235]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.4765], requires_grad=True)])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0], list(net[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88164b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters()) == list(net[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fb06508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.6666, -0.1235]]),\n",
       " Parameter containing:\n",
       " tensor([[-0.6666, -0.1235]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4765], requires_grad=True))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].state_dict()['weight'], net[0].weight, net[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f83faee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initialise w and b\n",
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5875b735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0033, 0.0126]]),\n",
       " Parameter containing:\n",
       " tensor([[0.0033, 0.0126]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].state_dict()['weight'], net[0].weight, net[0].bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052a632",
   "metadata": {},
   "source": [
    "# 3. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8f61e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2858e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835668a4",
   "metadata": {},
   "source": [
    "# 4. training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a0d8dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000106\n",
      "epoch 2, loss 0.000104\n",
      "epoch 3, loss 0.000104\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X), y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(features), labels)\n",
    "    print(f\"epoch {epoch + 1}, loss {l:f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "806ee065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[ 1.9990, -3.3995]])),\n",
       "             ('0.bias', tensor([4.2000]))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c0ed2",
   "metadata": {},
   "source": [
    "OOP design - Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98e620f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "device = \"cpu\"\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f39fb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a49c16d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0050, -0.0153,  0.0683,  0.0714, -0.0620, -0.0387, -0.0522,  0.0187,\n",
      "          0.0862,  0.0225]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f814a5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0993, 0.0973, 0.1058, 0.1062, 0.0929, 0.0951, 0.0938, 0.1007, 0.1077,\n",
       "          0.1011]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor(1., grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab, pred_probab.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da3911f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight, Size:torch.Size([512, 784])\n",
      "Layer: linear_relu_stack.0.bias, Size:torch.Size([512])\n",
      "Layer: linear_relu_stack.2.weight, Size:torch.Size([512, 512])\n",
      "Layer: linear_relu_stack.2.bias, Size:torch.Size([512])\n",
      "Layer: linear_relu_stack.4.weight, Size:torch.Size([10, 512])\n",
      "Layer: linear_relu_stack.4.bias, Size:torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name}, Size:{param.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b046b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
